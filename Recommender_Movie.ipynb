{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systema de Recomendaciones\n",
    "## VIDEO recomendation with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instalar from jupyter notebook console:\n",
    "\n",
    "pip install numpy <br>   #Dependency with vectors & matrix<br> <br> \n",
    "pip install scipy <br>   #Open source Math library & algorithms<br> <br> \n",
    "pip install lightfm<br>  #Recomendation algortihm including BPR & WARP.<br> \n",
    "\n",
    "##### NOTA: lightfm la instale con conda ya que pip me daba errores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 Import necesary libreries and dataset moduls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   # NumPy extensi√≥n de Python para trabajar con vectores y matrices\n",
    "from lightfm.datasets import fetch_movielens #importamos los modulos del fix fetch_movielens docstring\n",
    "from lightfm import LightFM  #libreria con algoritmo de recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the fetch_movielens method to see what it's doing <br>\n",
    "https://github.com/lyst/lightfm/blob/master/lightfm/datasets/movielens.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02 Fetch data and format it, we use the previous imported moduls and filter all values under 4 are not taking in account. Theoretically dataset must be normalized and ready to be use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_movielens(min_rating=4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03 We create our dictionay training and testing the data. Please check that training value is 10 times biger as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 49906 stored elements in COOrdinate format>\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 5469 stored elements in COOrdinate format>\n",
      "<1682x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 1682 stored elements in Compressed Sparse Row format>\n",
      "array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
      "       'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
      "       'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object)\n",
      "array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
      "       'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
      "       'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "print(repr(data['train']))\n",
    "print(repr(data['test']))\n",
    "print(repr(data['item_features']))\n",
    "print(repr(data['item_feature_labels']))\n",
    "print(repr(data['item_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04 create the prediction model for users based in exisitng Contents & Collaborative criterials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARP=Weighted Approximate-Rank Pairwise\n",
    "model = LightFM(loss='warp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "05 Once we have created the model we train it with the fit method using 3 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x10fcdf358>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model: Dataset, Number of epochs that must be run, Number of threads we want a run.\n",
    "model.fit(data['train'], epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06 Then we generete the recommendations for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use our model, our data an our userID for genererate de recomemdations\n",
    "\n",
    "def sample_recommendation(model, data, user_ids):\n",
    "\n",
    "    #number of users 942 and movies ID in training data\n",
    "    n_users, n_items = data['train'].shape\n",
    "\n",
    "    #generate recommendations for each user we input\n",
    "    for user_id in user_ids:\n",
    "\n",
    "        #Movies they already like, we use the compressed Sparse Row Format\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "\n",
    "        #movies our model predicts they will like\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        \n",
    "        #rank them in order of most liked to least, we make a top ten list.\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "\n",
    "        #print out the results\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "\n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "        print(\"     Recommended:\")\n",
    "\n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "07 we run the recomendation :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 42\n",
      "     Known positives:\n",
      "        Toy Story (1995)\n",
      "        Get Shorty (1995)\n",
      "        Twelve Monkeys (1995)\n",
      "     Recommended:\n",
      "        Star Wars (1977)\n",
      "        Toy Story (1995)\n",
      "        Sense and Sensibility (1995)\n",
      "User 200\n",
      "     Known positives:\n",
      "        Get Shorty (1995)\n",
      "        Seven (Se7en) (1995)\n",
      "        Usual Suspects, The (1995)\n",
      "     Recommended:\n",
      "        Pulp Fiction (1994)\n",
      "        Trainspotting (1996)\n",
      "        Fargo (1996)\n",
      "User 942\n",
      "     Known positives:\n",
      "        GoldenEye (1995)\n",
      "        Usual Suspects, The (1995)\n",
      "        Braveheart (1995)\n",
      "     Recommended:\n",
      "        Star Wars (1977)\n",
      "        Raiders of the Lost Ark (1981)\n",
      "        Terminator, The (1984)\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(model, data, [42, 200, 942])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESUME,\n",
    "1.- Recomendation algorithms help us make decision by learning our preferences.<br>\n",
    "2.- Two types of recomendations algorithms: Content Based & Collaborative.<br>\n",
    "3.- For start with building recomendation sistem LightFM is a good tool.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thanks for watching\n",
    "\n",
    "###### Cristhian Teran"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
